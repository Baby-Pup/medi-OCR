import os
import cv2
import numpy as np
import json
import warnings
import logging
from paddleocr import PaddleOCR
from openai import OpenAI

# ===== í™˜ê²½ ì„¤ì • =====
warnings.filterwarnings("ignore")
logging.getLogger("ppocr").setLevel(logging.ERROR)
os.environ["QT_QPA_PLATFORM"] = "xcb"

IMAGE_PATH = "/home/intel/Documents/medibuddy/OCR/OCR/medi-OCR/mediocr_test_result/Original_image/denpasa.png"

### ==========================================
### LLM SECTION: í´ë¼ì´ì–¸íŠ¸ ì„¤ì •
### ==========================================
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))


# ==========================================
# LLM: ë¬¸ì„œ ë¶„ë¥˜
# ==========================================
def classify_document(block_text):
    prompt = f"""
ë‹¤ìŒ í…ìŠ¤íŠ¸ê°€ ì–´ë–¤ ì¢…ë¥˜ì˜ ì˜ë£Œ ë¬¸ì„œì— í•´ë‹¹í•˜ëŠ”ì§€ í•œ ë‹¨ì–´ë¡œë§Œ ë‹µí•´ì¤˜.

- ì•½ì •ë³´
- ë³µì•½ì§€ë„ì„œ
- ì…ì›ì•ˆë‚´ì„œ

í…ìŠ¤íŠ¸:
{block_text}

ì¶œë ¥ í˜•ì‹: ì•½ì •ë³´ / ë³µì•½ì§€ë„ì„œ / ì…ì›ì•ˆë‚´ì„œ ì¤‘ í•˜ë‚˜ë§Œ
"""
    res = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{"role": "user", "content": prompt}]
    )
    return res.choices[0].message.content.strip()

# ==========================================
# LLM: ë¸”ë¡ ìš”ì•½
# ==========================================
def summarize_by_type(doc_type, block_text):
    if doc_type == "ì•½ì •ë³´":
        summary_prompt = f"""
ë‹¤ìŒ í…ìŠ¤íŠ¸ëŠ” ì˜ì•½í’ˆ ì•½ì •ë³´ì…ë‹ˆë‹¤.
í•µì‹¬ë§Œ 3ì¤„ë¡œ ì •ë¦¬í•´ì£¼ì„¸ìš”.

í…ìŠ¤íŠ¸:
{block_text}
"""
    elif doc_type == "ë³µì•½ì§€ë„ì„œ":
        summary_prompt = f"""
ë‹¤ìŒ í…ìŠ¤íŠ¸ëŠ” í™˜ìì—ê²Œ ì œê³µë˜ëŠ” ë³µì•½ì§€ë„ì„œì…ë‹ˆë‹¤.
í™˜ìê°€ ê¼­ ì•Œì•„ì•¼ í•  ë‚´ìš©ë§Œ 3ì¤„ë¡œ ìš”ì•½í•´ì£¼ì„¸ìš”.

í…ìŠ¤íŠ¸:
{block_text}
"""
    else:
        summary_prompt = f"""
ë‹¤ìŒ í…ìŠ¤íŠ¸ëŠ” ì…ì›ì•ˆë‚´ì„œ ê´€ë ¨ ë‚´ìš©ì…ë‹ˆë‹¤.
í™˜ìì˜ ì…ì› ì ˆì°¨ì™€ ê¸°ë³¸ ì•ˆë‚´ë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ 3ì¤„ ìš”ì•½í•´ì£¼ì„¸ìš”.

í…ìŠ¤íŠ¸:
{block_text}
"""
    res = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{"role": "user", "content": summary_prompt}]
    )
    return res.choices[0].message.content.strip()

# ==========================================
# ğŸ”¥ ìµœì¢… ë¬¸ì„œ ìš”ì•½ (ë„¤ ë²„ì „ ê·¸ëŒ€ë¡œ)
# ==========================================
def final_document_summary(block_result_json):
    client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
    prompt = f"""
ë‹¹ì‹ ì€ ì˜ë£Œ ë¬¸ì„œë¥¼ ë¶„ì„í•˜ëŠ” ì‹œìŠ¤í…œì…ë‹ˆë‹¤.
ì•„ë˜ëŠ” OCRê³¼ LLMì„ í†µí•´ block ë‹¨ìœ„ë¡œ ë¶„ì„ëœ JSONì…ë‹ˆë‹¤.
block_id ìˆœì„œëŒ€ë¡œ ë¬¸ë§¥ì„ ê³ ë ¤í•´ ì „ì²´ ë¬¸ì„œë¥¼ í†µí•© ë¶„ì„í•˜ê³ ,
ì•„ë˜ í˜•ì‹ìœ¼ë¡œë§Œ ë‹µí•˜ì‹­ì‹œì˜¤.

- ë¬¸ì„œì— í¬í•¨ëœ ë¬¸ì„œ íƒ€ì… ìš”ì•½ (ì˜ˆ: ì•½ì •ë³´ 4ê°œ, ë³µì•½ì§€ë„ì„œ 2ê°œ)
- ì „ì²´ ë¬¸ì„œì˜ ëª©ì  ìš”ì•½
- í™˜ìì—ê²Œ ê¼­ í•„ìš”í•œ í•µì‹¬ ì •ë³´ 3ê°€ì§€
"""
    response = client.responses.create(
        model="gpt-4.1",
        input=[
            {"role": "system", "content": prompt},
            {"role": "user", "content": json.dumps(block_result_json, ensure_ascii=False)}
        ]
    )
    return response.output_text

# ==========================================
# OCR ê´€ë ¨ í—¬í¼
# ==========================================
def cluster_text_boxes(bboxes, x_tol=20, y_tol=30):
    if not bboxes: return []
    clusters = []
    for box in bboxes:
        pts = np.array(box, dtype=np.float32)
        if pts.size == 8: pts = pts.reshape(4, 2)
        x1 = np.min(pts[:, 0]); x2 = np.max(pts[:, 0])
        y1 = np.min(pts[:, 1]); y2 = np.max(pts[:, 1])
        clusters.append([x1, y1, x2, y2])

    changed = True
    while changed:
        changed = False
        new_clusters = []
        visited = [False] * len(clusters)
        for i in range(len(clusters)):
            if visited[i]: continue
            base = clusters[i]
            visited[i] = True
            merged_something = True
            while merged_something:
                merged_something = False
                for j in range(len(clusters)):
                    if visited[j]: continue
                    target = clusters[j]
                    dist_x = max(0, target[0] - base[2], base[0] - target[2])
                    dist_y = max(0, target[1] - base[3], base[1] - target[3])
                    if dist_x < x_tol and dist_y < y_tol:
                        base[0] = min(base[0], target[0])
                        base[1] = min(base[1], target[1])
                        base[2] = max(base[2], target[2])
                        base[3] = max(base[3], target[3])
                        visited[j] = True
                        merged_something = True
                        changed = True
            new_clusters.append(base)
        clusters = new_clusters
    clusters.sort(key=lambda c: (int(c[1]/50), c[0]))
    return clusters

def extract_data_smart(result_item):
    extracted_data = []
    try:
        keys = list(result_item.keys()) if hasattr(result_item, 'keys') else []
        rec_texts = result_item['rec_texts'] if 'rec_texts' in keys else None
        dt_polys = result_item['dt_polys'] if 'dt_polys' in keys else None
        if rec_texts is None and 'res' in keys:
            return extract_data_smart(result_item['res'])
        if rec_texts is not None and dt_polys is not None:
            for i in range(len(rec_texts)):
                extracted_data.append({'text': rec_texts[i], 'bbox': dt_polys[i]})
            return extracted_data
    except:
        pass
    if isinstance(result_item, list):
        try:
            bbox = result_item[0]
            text_obj = result_item[1]
            text = text_obj[0] if isinstance(text_obj, (list, tuple)) else str(text_obj)
            return [{'text': text, 'bbox': bbox}]
        except:
            pass
    return []

# ==========================================
# ë©”ì¸ íŒŒì´í”„ë¼ì¸
# ==========================================
def main():
    print("="*50)
    print(f"OCR: {IMAGE_PATH}")
    print("="*50)

    if not os.path.exists(IMAGE_PATH):
        print("íŒŒì¼ ì—†ìŒ")
        return

    image = cv2.imread(IMAGE_PATH)
    if image is None: return

    print("âœ“ OCR ì‹¤í–‰ ì¤‘...")
    ocr = PaddleOCR(lang='korean', use_angle_cls=True)
    result = ocr.ocr(image)

    flat_data = []
    if isinstance(result, list):
        for item in result:
            data = extract_data_smart(item)
            if data: flat_data.extend(data)
            else:
                if isinstance(item, list):
                    for sub in item:
                        flat_data.extend(extract_data_smart(sub))

    print(f"ì´ {len(flat_data)}ê°œ í…ìŠ¤íŠ¸")

    all_bboxes = [item['bbox'] for item in flat_data]
    layout_clusters = cluster_text_boxes(all_bboxes, x_tol=30, y_tol=20)

    final_output = []
    for i, cluster in enumerate(layout_clusters):
        final_output.append({
            'id': i+1,
            'bbox': cluster,
            'texts': []
        })

    for item in flat_data:
        text = item['text']
        bbox = item['bbox']
        pts = np.array(bbox, dtype=np.float32)
        if pts.size == 8: pts = pts.reshape(4, 2)
        cx = np.mean(pts[:, 0])
        cy = np.mean(pts[:, 1])
        for section in final_output:
            sx1, sy1, sx2, sy2 = section['bbox']
            if sx1-5 <= cx <= sx2+5 and sy1-5 <= cy <= sy2+5:
                section['texts'].append({'text': text, 'cx': cx, 'cy': cy})
                break

    json_data = []
    for section in final_output:
        texts = section['texts']
        if not texts: continue
        texts.sort(key=lambda x: x['cy'])
        sorted_lines = []
        curr_line = [texts[0]]
        for i in range(1, len(texts)):
            if abs(texts[i]['cy'] - curr_line[-1]['cy']) < 15:
                curr_line.append(texts[i])
            else:
                curr_line.sort(key=lambda x: x['cx'])
                sorted_lines.extend(curr_line)
                curr_line = [texts[i]]
        curr_line.sort(key=lambda x: x['cx'])
        sorted_lines.extend(curr_line)
        full_content = " ".join([t['text'] for t in sorted_lines])
        json_data.append({'block_id': section['id'], 'content': full_content})

    # ==========================================
    # ğŸ”¥ LLM íŒŒì´í”„ë¼ì¸ ì ìš©
    # ==========================================
    llm_results = []
    print("\n=== LLM íŒŒì´í”„ë¼ì¸ ì‘ë™ ===")
    for block in json_data:
        block_text = block["content"]
        doc_type = classify_document(block_text)
        summary = summarize_by_type(doc_type, block_text)
        llm_results.append({
            "block_id": block["block_id"],
            "document_type": doc_type,
            "summary": summary
        })
        print(f"\n[Block {block['block_id']}]")
        print(f"- ë¬¸ì„œíƒ€ì…: {doc_type}")
        print(f"- ìš”ì•½: {summary}")

    with open("llm_output.json", "w", encoding="utf-8") as f:
        json.dump(llm_results, f, ensure_ascii=False, indent=4)

    print("\nì™„ë£Œ! â†’ llm_output.json ì €ì¥")

    # ==========================================
    # ğŸ”¥ ìµœì¢… ë¬¸ì„œ ìš”ì•½
    # ==========================================
    print("\n=== ìµœì¢… ë¬¸ì„œ ìš”ì•½ ìƒì„± ===")
    summary_text = final_document_summary(llm_results)
    print("\n===== ìµœì¢… ìš”ì•½ =====")
    print(summary_text)

    with open("final_summary.txt", "w", encoding="utf-8") as f:
        f.write(summary_text)
    print("\nì™„ë£Œ! â†’ final_summary.txt ì €ì¥")

if __name__ == "__main__":
    main()